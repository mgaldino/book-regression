# - Revisão de estatística e probabilidade

A média de um conjunto de valores é dada pela soma dos valores, dividido pelo número de observações. Matematicamente:
$media = \sum_{i=1}^n{x_i}/n$ para observações $\{ x_1, x_2, x_3, ..., x_n \}$

Em geral, as observações são uma amostra, e falamos de média amostral, $\overline x$. Ou seja:

$\overline x = \sum_{i=1}^n{x_i}/n$

Exercício 1. Vamos calcular, no R, a média das seguintes amostras:

a) $\{1,2,3,4,5,6,7,8,9,10\}$

b) $\{5,5,5,5,5,5,5\}$

c) $\{1,3,5,7,9,11\}$

d) $\{-5,-4,-3,-2,-1,1,2,3,4,5\}$

Código no R

```{r cap3}
x <- c(1,2,3,4,5,6,7,8,9,10)
(media_x <- sum(x)/length(x))

x <- c(5,5,5,5,5,5,5)
(media_x <-  sum(x)/length(x))

x <- c(1,3,5,7,9,11)
(media_x <-  sum(x)/length(x))

x <- c(-5,-4,-3,-2,-1,1,2,3,4,5)
(media_x <-  sum(x)/length(x))

# ou podemos simplemsnte usar mean(x)
mean(x)
```



## Variável Aleatória

Uma variável aleatória (v.a.) mede numericamente resultados de eventos aleatórios. Por exemplo, um dado de $6$ faces possui um espaço amostral de eventos possíveis dados pelos números $\{1,2,3,4,5,6\}$. Ao atribuirmos uma probabilidade a cada resultado possível do espaço amostral, por exemplo $1/6$, temos uma distribuição de probabilidade.

Variáveis aleatórias podem ser discretas ou contínuas. Uma v.a. discreta pode assumir um número finito (contável) de valores. Já uma contínua pode assumir infinitos (não-contáveis) valores.

Um conjunto é contável se ele for finito ou se puder ser estabelecida uma correspondência um para um com o conjunto (infinito) dos números naturais.

## Esperança matemática

A esperança de uma variável aleatória discreta $X$, cuja probabilidade de massa de $x \in X$ é dada por $p(x)$, é definida por: $\sum(x*p(x))$.

A esperança de uma v.a. contínua X, cuja densidade é $f(x)$, é definida por: $\int f(x)*x\,dx$.

Similarmente, para a mesma v.a. X acima, a esperança de uma função $h(X)$ é dada por  $\int f(x)*h(x)\,dx$ e analogamente para o caso discreto.

## Variância

A variância de uma variável aleatória $X$ é dada por:

Definição 1. $Var(X) = \mathbb{E}[(X - \mathbb{E}[X])^2]$.

A Covariância de duas v.a. $X$ e $Y$ é definida como:
$Cov(X,Y) = \mathbb{E}[(X -  \mathbb{E}[X])*(Y -  \mathbb{E}[Y])]$.

Notem que $Cov(X,X) = Var(X)$.

A covariância é positiva quando ambos X e Y tendem a ter valores acima (ou abaixo) de sua média simultaneamente, enquanto ela é negativa quando uma v.a. tende a ter valores acima da sua média e a outra abaixo.

## Álgebra com Esperança, Variância e Covariância

Sejam $a$ e $b$ constantes.

1.  Linearidade da Esperança
$\mathbb{E}[aX + bY] =\mathbb{E}[aX] + \mathbb{E}[by] =  a*\mathbb{E}[X] + b*\mathbb{E}[Y]$

Exercício: verifique, com exemplos, que isso é verdade.

2. Identidade da variância

 $Var(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - \mathbb{E}^2[X]$
 
 A prova será demonstrada mais adiante.

3. Identidade da Covariância

$Cov(X,Y) = \mathbb{E}[X*Y] - \mathbb{E}[X]*\mathbb{E}[Y] =  \mathbb{E}[(X -  \mathbb{E}[X])*(Y -  \mathbb{E}[Y])]$

Exercício para o leitor. Prove que isso é verdade.

4, Covariância é simétrica

$Cov(X,Y) = Cov(Y,X)$

5. Variância não é linear
$Var(a*X + b) = a^2*Var(x)$

6. Covariância não é linear

 $Cov(a*X + b,Y) = a*Cov(Y,X)$
 
## Prova da identidade da variância

Vamos mostrar que $\mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - \mathbb{E}^2[X]$

1. Começamos expandido o quadrado da esperança:
$Var(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[(X - \mathbb{E}[X]) * (X - \mathbb{E}[X])]$.

2. Aplicando a regra do quadrado, temos:
$\mathbb{E}[(X - \mathbb{E}[X]) * (X - \mathbb{E}[X])] = \mathbb{E}[(X^2 - 2* \mathbb{E}[X]*X + \mathbb{E}[X]^2)]$

3. Pela propriedade da experança, sabemos que, sejam $A$ e $B$ duas v.a. independentes, então $\mathbb{E}[A + B] = \mathbb{E}[A] + \mathbb{E}[B]$. Então:

$Var(X) = \mathbb{E}[X^2] - \mathbb{E}[2*\mathbb{E}[X]*X] + \mathbb{E}[\mathbb{E}[X]^2]]$

4. Outra propriedade da esperança é que, seja $a$ uma constante e $X$ uma v.a., então $\mathbb{E}[a*X] = a*\mathbb{E}[X]$.


$Var(X) = \mathbb{E}[X^2] - 2*\mathbb{E}[\mathbb{E}[X]*X] + \mathbb{E}[\mathbb{E}[X]^2]]$

5. Nós sabemos que $\mathbb{E}[X]$ é uma constante (é uma média da v.a.). E a média de uma constante é a própria constante. Portanto, $\mathbb{E}[\mathbb{E}[X]] = \mathbb{E}[X]$. E usaremos também que $\mathbb{E}[a*X] = a*\mathbb{E}[X]$ e, por fim, o fato de que uma constante ao quadrado é em si uma constante.

$Var(X) = \mathbb{E}[X^2] - 2*\mathbb{E}[X] * \mathbb{E}[\mathbb{E}[X]] + \mathbb{E}[X]^2$

$Var(X) = \mathbb{E}[X^2] - 2*\mathbb{E}[X] * \mathbb{E}[X] + \mathbb{E}[X]^2$

$Var(X) = \mathbb{E}[X^2] - 2*\mathbb{E}[X]^2 + \mathbb{E}[X]^2$

$Var(X) = \mathbb{E}[X^2] - \mathbb{E}[X]^2$

Como Queriamos Demonstrar (CQD).



## Distribuição de Probabilidade Conjunta

A Distribuição de probabilidade conjunta de $X$ e $Y$ (definida no mesmo espaço de probabilidade) é uma distribuição de probabilidade dos pares $(x,y)$ e descreve como os valores de $X$ e $Y$ variam conjuntamente. Cada uma das distribuições $X$ e $Y$ sozinhas são chamadas de distribuições marginais. Uma distribuição conjunta é como uma máquina que, de acordo com certas regras de probabilidade, retorna dois pares de valores.

ex. 1.
Roleta. Em um casino, um jogo comum é a roleta. Ela consiste normalmente de 32 números (0 a 31), e cada número tem uma cor (preto, vermelho ou verde). Ao girar a roleta, ela solta um número e uma cor. Portanto, podemos pensar que a roleta é uma distribuição conjunta de duas variáveis (números e cores).

Ex. 2.:
Considere um dado de 4 faces $( 1, 2, 3, 4 )$. Seja $X$ a soma dos números dos dois dados, e $Y$ o maior valor dos dois dados. O espaço amostral é dado pela tabela abaixo.


```{r cap3 tab1, results='asis', message=FALSE}
library(knitr)
library(dplyr)
library(kableExtra)
#Definir o espaço amostral

espaco_amostral <- expand.grid(1:4, 1:4)
espaco_amostral$X <- espaco_amostral$Var1 + espaco_amostral$Var2
espaco_amostral$Y <- pmax(espaco_amostral$Var1, espaco_amostral$Var2)

# Criar a tabela
kable(espaco_amostral, col.names = c("resultado do primeiro dado", "resultado do segundo dado", "X", "Y"),
                caption = "Tabela representando a soma (X) and o maior valor (Y) do lançamento de dois dados de quatro lados") %>%
 kable_styling(bootstrap_options = "striped")


```

Se supusermos que todos os números possuem a mesma chance de sair quando jogamos os dados, então, a distribuição conjunta de $X$ e $Y$ pode ser dada por:

```{r cap3 dado, results='asis'}

# Definir os valores de (x, y) e P(X = x, Y = y)
valores <- c("(2, 1)", "(3, 2)", "(4, 2)", "(4, 3)", "(5, 3)", "(5, 4)", "(6, 3)", "(6, 4)", "(7, 4)", "(8, 4)")
probabilidades <- c(0.0625, 0.1250, 0.0625, 0.1250, 0.1250, 0.1250, 0.0625, 0.1250, 0.1250, 0.0625)

# Criar a tabela
tabela <- data.frame("(x, y)" = valores, "P(X = x, Y = y)" = probabilidades)

# Formatar a tabela
kable(tabela, caption = "Tabela representando a distribuição conjunta da soma (X) e o maior (Y) de dois lançamentos de um dado de quatro faces",
                          col.names = c("$(X,Y)$", "$P(X=x, Y=y)$")) %>%
  kable_styling(bootstrap_options = "striped")


```

## Probabilidade Condicional

Nós vimos o que é uma distribuição de probabilidade conjunta. É comum que nós tenhamos apenas uma observação parcial sobre uma das variáveis. Digamos, que $y = 2$. De posse dessa informação, como podemos atualizar nossa tabela de probabilidades? Se o maior valor foi $2$, então a soma dos dados $X$ só pode ser 3 ou 4. Se a soma for 3, temos algo como $(1,2)$ ou $(2,1)$. Se a soma for 4, então deve ter saído $(2,2)$. Esse é o novo espaço amostral dado que $y=2$.Todos os outros números não podem ocorrer e, portanto, possuem probabilidade zero. Logo, $P(X=1|Y=2) = 2/3$ e $P(X=2|Y=2) = 1/3$.

Isso é o que chamamos de probabilidade condicional. No caso, a probabilidade condicional de $X$, dado $Y=y$.

A probabilidade condicional é em si uma distribuição de probabilidade. Do mesmo jeito que temos as distribuições de probabilidade de $X$, de $Y$ e de $X,Y$, também temos a de $X|y=y$ (e, claro, a de $Y|X=x$). A tabela abaixo apresenta essa distribuição de probabilidade condicional para o caso de $Y=2$.



```{r cap3 prob-cond, results='asis'}

# Definir os valores de (x, y) e P(X = x, Y = y)
valores <- c("(2, 1)", "(3, 2)", "(4, 2)", "(4, 3)", "(5, 3)", "(5, 4)", "(6, 3)", "(6, 4)", "(7, 4)", "(8, 4)")
probabilidades <- c(0, 2/3, 1/3, 0, 0, 0, 0, 0, 0, 0)

# Criar a tabela
tabela <- data.frame("(x, y)" = valores, "P(X = x| Y = 2)" = probabilidades)

# Formatar a tabela
kable(tabela, caption = "Tabela representando a distribuição conjunta da soma (X) e o maior (Y) de dois lançamentos de um dado de quatro faces",
                          col.names = c("$(X,Y)$", "$P(X=x| Y=2)$")) %>%
  kable_styling(bootstrap_options = "striped")


```

## Esperança Condicional

Se a probabilidade condicional é uma distribuição de probabilidade no seu próprio direito, então podemos calcular a esperança dessa distribuição, exatamente como fazíamos antes. No caso, falamos de esperança condicional. Qual o valor médio de $X$, quando $Y=2$? 

$3*(2/3) + 4*(1/3)$
$2 + 4/3 = 6/3 + 4/3 = 10/3 = 3.333$

A notação matemática para a esperança condicional, nesse caso, é: $E[X|Y=2]$.