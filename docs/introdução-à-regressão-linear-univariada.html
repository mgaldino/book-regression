<!DOCTYPE html>
<html lang="pt" xml:lang="pt">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Introdução à regressão linear univariada | Introdução à Regresssão para Ciências Sociais</title>
  <meta name="description" content="Capítulo 5 Introdução à regressão linear univariada | Introdução à Regresssão para Ciências Sociais" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Introdução à regressão linear univariada | Introdução à Regresssão para Ciências Sociais" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Introdução à regressão linear univariada | Introdução à Regresssão para Ciências Sociais" />
  
  
  

<meta name="author" content="Manoel Galdino" />


<meta name="date" content="2023-08-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introdução-à-simulação.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introdução à Regressão</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> - Prefácio</a></li>
<li class="chapter" data-level="2" data-path="revisão-de-r.html"><a href="revisão-de-r.html"><i class="fa fa-check"></i><b>2</b> - Revisão de R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="revisão-de-r.html"><a href="revisão-de-r.html#r-e-rstudio"><i class="fa fa-check"></i><b>2.1</b> R e Rstudio</a></li>
<li class="chapter" data-level="2.2" data-path="revisão-de-r.html"><a href="revisão-de-r.html#r-como-calculadora"><i class="fa fa-check"></i><b>2.2</b> R como calculadora</a></li>
<li class="chapter" data-level="2.3" data-path="revisão-de-r.html"><a href="revisão-de-r.html#objetos-no-r"><i class="fa fa-check"></i><b>2.3</b> Objetos no R</a></li>
<li class="chapter" data-level="2.4" data-path="revisão-de-r.html"><a href="revisão-de-r.html#tipos-de-objetos"><i class="fa fa-check"></i><b>2.4</b> Tipos de objetos</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="revisão-de-r.html"><a href="revisão-de-r.html#numeric"><i class="fa fa-check"></i><b>2.4.1</b> Numeric</a></li>
<li class="chapter" data-level="2.4.2" data-path="revisão-de-r.html"><a href="revisão-de-r.html#character"><i class="fa fa-check"></i><b>2.4.2</b> character</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="revisão-de-r.html"><a href="revisão-de-r.html#armazenando-dados"><i class="fa fa-check"></i><b>2.5</b> Armazenando dados</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="revisão-de-r.html"><a href="revisão-de-r.html#vetor"><i class="fa fa-check"></i><b>2.5.1</b> Vetor</a></li>
<li class="chapter" data-level="2.5.2" data-path="revisão-de-r.html"><a href="revisão-de-r.html#matriz"><i class="fa fa-check"></i><b>2.5.2</b> Matriz</a></li>
<li class="chapter" data-level="2.5.3" data-path="revisão-de-r.html"><a href="revisão-de-r.html#data-frame"><i class="fa fa-check"></i><b>2.5.3</b> Data Frame</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="revisão-de-r.html"><a href="revisão-de-r.html#bibliotecaspacotes"><i class="fa fa-check"></i><b>2.6</b> Bibliotecas/pacotes</a></li>
<li class="chapter" data-level="2.7" data-path="revisão-de-r.html"><a href="revisão-de-r.html#importando-dados"><i class="fa fa-check"></i><b>2.7</b> importando dados</a></li>
<li class="chapter" data-level="2.8" data-path="revisão-de-r.html"><a href="revisão-de-r.html#data-wrangling"><i class="fa fa-check"></i><b>2.8</b> Data wrangling</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="revisão-de-estatística-e-probabilidade.html"><a href="revisão-de-estatística-e-probabilidade.html"><i class="fa fa-check"></i><b>3</b> - Revisão de estatística e probabilidade</a>
<ul>
<li class="chapter" data-level="3.1" data-path="revisão-de-estatística-e-probabilidade.html"><a href="revisão-de-estatística-e-probabilidade.html#variável-aleatória"><i class="fa fa-check"></i><b>3.1</b> Variável Aleatória</a></li>
<li class="chapter" data-level="3.2" data-path="revisão-de-estatística-e-probabilidade.html"><a href="revisão-de-estatística-e-probabilidade.html#esperança-matemática"><i class="fa fa-check"></i><b>3.2</b> Esperança matemática</a></li>
<li class="chapter" data-level="3.3" data-path="revisão-de-estatística-e-probabilidade.html"><a href="revisão-de-estatística-e-probabilidade.html#variância"><i class="fa fa-check"></i><b>3.3</b> Variância</a></li>
<li class="chapter" data-level="3.4" data-path="revisão-de-estatística-e-probabilidade.html"><a href="revisão-de-estatística-e-probabilidade.html#algebra-com-esperança-variância-e-covariância"><i class="fa fa-check"></i><b>3.4</b> Algebra com Esperança, Variância e Covariância</a></li>
<li class="chapter" data-level="3.5" data-path="revisão-de-estatística-e-probabilidade.html"><a href="revisão-de-estatística-e-probabilidade.html#distribuição-de-probabilidade-conjunta"><i class="fa fa-check"></i><b>3.5</b> Distribuição de Probabilidade Conjunta</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introdução-à-simulação.html"><a href="introdução-à-simulação.html"><i class="fa fa-check"></i><b>4</b> Introdução à Simulação</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="introdução-à-simulação.html"><a href="introdução-à-simulação.html#configuraçao"><i class="fa fa-check"></i><b>4.0.1</b> Configuraçao</a></li>
<li class="chapter" data-level="4.0.2" data-path="introdução-à-simulação.html"><a href="introdução-à-simulação.html#simular"><i class="fa fa-check"></i><b>4.0.2</b> Simular</a></li>
<li class="chapter" data-level="4.0.3" data-path="introdução-à-simulação.html"><a href="introdução-à-simulação.html#resumir"><i class="fa fa-check"></i><b>4.0.3</b> Resumir</a></li>
<li class="chapter" data-level="4.1" data-path="introdução-à-simulação.html"><a href="introdução-à-simulação.html#análise-de-sensibilidade"><i class="fa fa-check"></i><b>4.1</b> Análise de sensibilidade</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html"><i class="fa fa-check"></i><b>5</b> Introdução à regressão linear univariada</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#esperança-condicional"><i class="fa fa-check"></i><b>5.1</b> Esperança Condicional</a></li>
<li class="chapter" data-level="5.2" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#cef"><i class="fa fa-check"></i><b>5.2</b> CEF</a></li>
<li class="chapter" data-level="5.3" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#objetivos-de-aprendizagem-ao-final-do-capítulo"><i class="fa fa-check"></i><b>5.3</b> Objetivos de aprendizagem ao final do capítulo</a></li>
<li class="chapter" data-level="5.4" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#this-week"><i class="fa fa-check"></i><b>5.4</b> This week</a></li>
<li class="chapter" data-level="5.5" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#coming-attractions"><i class="fa fa-check"></i><b>5.5</b> Coming Attractions</a></li>
<li class="chapter" data-level="5.6" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#conditional-expectation-function-cef"><i class="fa fa-check"></i><b>5.6</b> Conditional Expectation Function (CEF),</a></li>
<li class="chapter" data-level="5.7" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#part-i"><i class="fa fa-check"></i><b>5.7</b> Part I</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#part-ii"><i class="fa fa-check"></i><b>5.7.1</b> Part II</a></li>
<li class="chapter" data-level="5.7.2" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#part-iii"><i class="fa fa-check"></i><b>5.7.2</b> Part III</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#computing-the-cef"><i class="fa fa-check"></i><b>5.8</b> Computing the CEF</a></li>
<li class="chapter" data-level="5.9" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#simple-quantities"><i class="fa fa-check"></i><b>5.9</b> Simple Quantities</a></li>
<li class="chapter" data-level="5.10" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#conditional-quantities"><i class="fa fa-check"></i><b>5.10</b> Conditional Quantities</a></li>
<li class="chapter" data-level="5.11" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#conditional-expectaiton"><i class="fa fa-check"></i><b>5.11</b> Conditional Expectaiton</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#conditional-expectation"><i class="fa fa-check"></i><b>5.11.1</b> Conditional Expectation</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#minimizing-the-mse"><i class="fa fa-check"></i><b>5.12</b> Minimizing the MSE</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#minimizing-mse"><i class="fa fa-check"></i><b>5.12.1</b> Minimizing MSE</a></li>
<li class="chapter" data-level="5.12.2" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#the-pudding-aka-where-the-proof-is"><i class="fa fa-check"></i><b>5.12.2</b> The pudding (aka: “Where the proof is”)</a></li>
<li class="chapter" data-level="5.12.3" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#the-implication"><i class="fa fa-check"></i><b>5.12.3</b> The Implication</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#working-with-the-blp"><i class="fa fa-check"></i><b>5.13</b> Working with the BLP</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#professorial-mistakes-discrete-rvs"><i class="fa fa-check"></i><b>5.13.1</b> Professorial Mistakes (Discrete RVs)</a></li>
<li class="chapter" data-level="5.13.2" data-path="introdução-à-regressão-linear-univariada.html"><a href="introdução-à-regressão-linear-univariada.html#continuous-blp"><i class="fa fa-check"></i><b>5.13.2</b> Continuous BLP</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introdução à Regresssão para Ciências Sociais</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introdução-à-regressão-linear-univariada" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Capítulo 5</span> Introdução à regressão linear univariada<a href="introdução-à-regressão-linear-univariada.html#introdução-à-regressão-linear-univariada" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>O modelo de regressão (não confundir com regressão linear) é uma forma bem ampla de modelar os dados para prever uma variável de interesse, usualmente designada pela letra <span class="math inline">\(Y\)</span>. Se eu quero prever os votos de candidatas em uma eleição, a votação de cada candidata é minha variável de interesse, <span class="math inline">\(Y\)</span>. Digamos que eu tenho uma amostra da intenção de votos das candidatas, obtidas por meio de uma pesquisa eleitoral.</p>
<p>Há muitas formas de apresentar ou motivar regressão linear. O método mais tradicional é pensar que a regressão linear é uma reta que é ajustada aos pontos observados. Porém, não tomaremos esse caminho aqui.</p>
<p>Nós iremos tomar aqui o caminho de considerar que a regressão linear é uma formade aproximar a chamada “Conditional Regression Function” (CEF, na sigla em inglês). O objetivo é entender “as far as possible with the available data how the conditional distribution of some response y varies across subpopulations determined by the possible values of the predictor or predictors” (Cook and Weisberg, apud Berk, p. 4).</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre><code>## # A tibble: 1 × 1
##   `mean(pib_per_capita)`
##                    &lt;dbl&gt;
## 1                 17389.</code></pre>
<pre><code>## # A tibble: 2 × 2
##   amazonia_legal `mean(pib_per_capita)`
##   &lt;chr&gt;                           &lt;dbl&gt;
## 1 Não                            17953.
## 2 Sim                            13883.</code></pre>
<p>Portanto, vamos retomrar o conceito de esperança condicional, para introduzir em seguida a função de regressão condicional (CEF, em inglÊs) e então como a regressão pode ser pensada como uma forma de aproximar a CEF.</p>
<div id="esperança-condicional" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Esperança Condicional<a href="introdução-à-regressão-linear-univariada.html#esperança-condicional" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Uma das primeiras distinções que temos de fazer é sobre previsão e explicação (causal). Quando queremos prever, estamos interessados em saber quais os provaveis valores de variáveis no futuro, a parte de informações sobre a própria variável e outras no passado. Nesse sentido, é preciso algum tipo de suposição de que o futuro se assemelha ao passado de algum modo. Esse tipo de suposição usualmente toma a forma de um modelo probabilísitco, mas não apenas.</p>
<p>Quando estamos interessados em explicações causais, temos dois tipos de perguntas de pesquisa possíveis. Uma sobre a chamada causa dos efeitos e outra sobre o efeito das causas (Gelman &amp; Imbens, 2013). A causa dos efeitos são perguntas do tipo: o que causal a II Grande Guerra? Ou qual a causa da eleição de Trump ou Bolsonaro? O que explica a desigualdade de renda no Brasil? São todas perguntas em que queremos explicar um efeito, isto é, identificar as causas de um fenômeno (efeito). Já o efeito das causas ão perguntas do tipo: qual o efeito da vacina de covid-19 sobre a mortalidade por Covid-19? Qual o efeito de checagem de notícias sobre a crença de pessoas em desinformação? Qual o efeito da magnitude eleitoral sobre fragmentação partidária? E assim por diante. Aqui, estamos interessados em entender o efeito causal de uma variável sobre outra, sem pretender esgotar todas as explicações de causa possíveis.</p>
<p>A maior parte dos métodos quantitativos existentes são bons para responder perguntas de previsão e de causa dos efeitos. Grosso modo, não há método quantitativo para estimação do efeito das causas, exceto realizar uma série de estudos independentes sobre várias causas dos efeitos, olhando uma causa distinta do mesmo efeito por vez e esperar que isso gere um conhecimento combinado sobre essas múltiplas causas. Mas não há, contudo, uma metodologia bem definida de como combinar esses estudos independentes em um único conhecimento do efeito conjunto das causas.</p>
<p>Assim, nosso curso será dedicado apenas a modelos de previsão e modelos de causa dos efeitos, que é o que temos de metodologias já desenvolvidas e consolidadas. Começamos por essa explicação porque uma perspectiva mais antiga, e ainda comum nas ciências sociais, é que modelos de regressão múltiplas permitem estimar o efeito de várias causas. Isso raramente é o caso e não adotaremos essa perspecitva aqui <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
</div>
<div id="cef" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> CEF<a href="introdução-à-regressão-linear-univariada.html#cef" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O que consgtitui uma boa previsão? Tradicionalmente, empregamos a noção de Erro Quadrátco Médio (EQM) para quantificar boas previsões. Quanto menor o EQM, melhor uma previsão. Se o objetivo é, portanto, fazer previsões que minimizem o EQM, iremos apresertar e mostrar que a Função de Esperança Condicional (<em>CEF</em>, na sigla em inglês) é o melhor preditor global possível. Vamos dizer em outras palavras, porque esse resultado é verdadeiramente icnrível. A CEF é o melhor preditor possível dentre todos que existam ou possam vir a existir, entendendo melhor como ter o menor EQM. Por isso que a CEF é o ponto de partida de qualquer preditor que exista, seja uma regressão simples ou algoritmos de aprendizens de máquinas como “random forest” ou mesmo algorítimos de deep learning de redes neurais por traz dos recentes avanços na inteligência artificial.</p>
<blockquote>
<p>Mesmo os algorítmos mais avançados de inteleigência artificial, como os <strong>Large Language Models</strong>, que estão na base de ferramentas como ChatGPT, <em>não podem</em> ter desempenho melhor que a função de experança condicional, CEF, ao fazer uma previsão.</p>
</blockquote>
<p>Naturalmente, se esse é o caso, a próxima pergunta que todos nós iremos fazer é: por que não aprender apenas a usar a CEF, que é o melhor preditor possível, e ser feliz para sempre? Porque a natureza não nos diz qual é a CEF. Nós nunca sabemos qual a verdadeira função de esperança condicional. Então tentamos aproximar o melhor possível a CEF, a partir de simplificações da realidade. Em particular, nosso curso pode ser pensado em torno das seguintes perguntas: como aproximar a CEF por meio de regressão linear (combinação lineares de preditores)? Quais as propridades dessa aproximação? Em que condições ela é uma boa aproximação e em que sentido (quantitativo e preciso) podemos falar de boa aproximação? Mais para o final do curso faremos a conexão entre a CEF, modelos preditivos e modelos causais.</p>
</div>
<div id="objetivos-de-aprendizagem-ao-final-do-capítulo" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Objetivos de aprendizagem ao final do capítulo<a href="introdução-à-regressão-linear-univariada.html#objetivos-de-aprendizagem-ao-final-do-capítulo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Estudantes deverão ter aprendido ao final do capítulo:</p>
<ol style="list-style-type: decimal">
<li><strong>Reconhecer</strong> que a função de esperança condicional, a <em>CEF</em>, em sua forma pura, é o melhor preditor possível para uma variável alvo, dadas as informações de outras variáveis.</li>
<li><strong>Memorizar</strong> que todos os outros predidores, sejam lineares ou não-lineares, incluindo preditores de deep learning, são tentativas de aproximar a CEF.</li>
<li><strong>Apreciar</strong> que o melhor predito linear (isto é, considerando apenas preditores que incluem combinação lineares de variáveis) produz previsões razoáveis, e <strong>antecipar</strong> que esse preditor noe leva à regressão linear. t</li>
</ol>
</div>
<div id="this-week" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> This week<a href="introdução-à-regressão-linear-univariada.html#this-week" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>We look at situations with one or more “input” random variables, and one “output.”</li>
<li>Conditional expectation summarizes the output, given values for the inputs.</li>
<li>The conditional expectation function (CEF) is a predictor – a function that yields a value for the output, give values for the inputs.</li>
<li>The best linear predictor (BLP) summarizes a relationship using a line / linear function.</li>
</ul>
</div>
<div id="coming-attractions" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Coming Attractions<a href="introdução-à-regressão-linear-univariada.html#coming-attractions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>OLS regression is a workhorse of modern statistics, causal analysis, etc
<ul>
<li>It is also the basis for many other models in classical stats and machine learning</li>
</ul></li>
<li>The target that OLS estimates is exactly the BLP, which we’re learning about this week.</li>
</ul>
</div>
<div id="conditional-expectation-function-cef" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Conditional Expectation Function (CEF),<a href="introdução-à-regressão-linear-univariada.html#conditional-expectation-function-cef" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="part-i" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Part I<a href="introdução-à-regressão-linear-univariada.html#part-i" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Vamos lembrar como definimos a esperança de <span class="math inline">\(Y\)</span> para o caso discreto:</p>
<p>A esperança de uma variável aleatória discreta <span class="math inline">\(Y\)</span>, cuja probabilidade de massa de <span class="math inline">\(y \in Y\)</span> é dada por <span class="math inline">\(p(x)\)</span>, é definida por:</p>
<p><span class="math display">\[
E[Y] = \sum(y*p(y))
\]</span>.</p>
<p>No caso contínuo, temos de usar integral.</p>
<p><span class="math display">\[
E[Y] = \int y*f(y)\,dy
\]</span>.</p>
<p>Agora, precisamos de um novo conceito, que é a esperança concicional de <span class="math inline">\(Y\)</span> dado que <span class="math inline">\(X = x\)</span>.</p>
<p><span class="math display">\[
  E[Y|X=x] =  \sum(y*p(y|X=x))
\]</span></p>
<div id="part-ii" class="section level3 hasAnchor" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Part II<a href="introdução-à-regressão-linear-univariada.html#part-ii" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>What desirable properties of a predictor does the expectation possess (note, this is thinking <em>back</em> by a week)? What makes these properties desirable?</li>
<li>Turning to the content from this week, how, if at all, does the conditional expectation improve on these desirable properties?</li>
</ol>
</div>
<div id="part-iii" class="section level3 hasAnchor" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Part III<a href="introdução-à-regressão-linear-univariada.html#part-iii" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Compare and contrast <span class="math inline">\(E[Y]\)</span> and <span class="math inline">\(E[Y|X]\)</span>. For example, when you look at how these operators are “shaped”, how are their components similar or different?<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p></li>
<li><p>What is <span class="math inline">\(E[Y|X]\)</span> a function of? What are “input” variables to this function?</p></li>
<li><p>What, if anything, is <span class="math inline">\(E[E[Y|X]]\)</span> a function of?</p></li>
<li><p>(Question 1) In both, we have a probability density function multiplied by the values that we realize; this is basically serving as a “weighting” function, we’re merely changing what that weighting function is!</p></li>
<li><p>In both cases we’re looking at a “mean” of a distribution – in one it is just a “conditional mean” than a “marginal mean”.</p></li>
<li><p>(Question 2) We integrate <span class="math inline">\(Y\)</span> out completely by using its every value in the integral, so <span class="math inline">\(E\)</span> will not have <span class="math inline">\(Y\)</span> in the answer – instead, it will remain a function of <span class="math inline">\(X\)</span>.</p></li>
<li><p><span class="math inline">\(f_{Y|X=x}\)</span> is a function of <span class="math inline">\(x\)</span>! So, the conditional expectation is some function <span class="math inline">\(x\)</span> as well.</p></li>
<li><p>(Optional to discuss; probably too minute) An observation that some parsing students will make:</p>
<ul>
<li>Without fixing <span class="math inline">\(X\)</span> to some realization (denoted as a “little x”, <span class="math inline">\(x\)</span>, then <span class="math inline">\(E[Y|X]\)</span> is a function of <span class="math inline">\(X\)</span> and so the whole statement is a function of a random variable (i.e. <span class="math inline">\(E[Y|X]\)</span> is <em>itself</em> a RV).</li>
<li>Once we fix <span class="math inline">\(X=x\)</span>, then <span class="math inline">\(E[Y|X=x]\)</span> is fixed to some constant – there is one value that <span class="math inline">\(E[Y|X=x]\)</span> maps to.</li>
</ul></li>
<li><p>(Question 3) That isn’t a function of anything! Once you’ve computed <span class="math inline">\(E[E[Y|X]]\)</span>, you’ve integrated out all variables!</p></li>
</ul>
</div>
</div>
<div id="computing-the-cef" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Computing the CEF<a href="introdução-à-regressão-linear-univariada.html#computing-the-cef" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Suppose that random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are jointly continuous, with joint density function given by,</li>
</ul>
<p><span class="math display">\[
f(x,y) =
  \begin{cases}
    2, &amp; 0 \leq x \leq 1, 0 \leq y \leq x \\
    0, &amp; otherwise
\end{cases}
\]</span></p>
<p>What does the joint PDF of this function look like?</p>
<p><img src="bookdownproj_files/figure-html/create%20blank%20plot%20for%20pdf-1.png" width="672" /></p>
</div>
<div id="simple-quantities" class="section level2 hasAnchor" number="5.9">
<h2><span class="header-section-number">5.9</span> Simple Quantities<a href="introdução-à-regressão-linear-univariada.html#simple-quantities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To begin with, let’s compute the simplest quantities:</p>
<ul>
<li>What is the expectation of <span class="math inline">\(X\)</span>?</li>
<li>What is the expectation of <span class="math inline">\(Y\)</span>?</li>
<li>How would you compute the variance of <span class="math inline">\(X\)</span>? (We’re not going to do it live).</li>
</ul>
</div>
<div id="conditional-quantities" class="section level2 hasAnchor" number="5.10">
<h2><span class="header-section-number">5.10</span> Conditional Quantities<a href="introdução-à-regressão-linear-univariada.html#conditional-quantities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="conditional-expectaiton" class="section level2 hasAnchor" number="5.11">
<h2><span class="header-section-number">5.11</span> Conditional Expectaiton<a href="introdução-à-regressão-linear-univariada.html#conditional-expectaiton" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>And then, let’s think about how to compute the conditional quantities. To get started, you can use the fact that in week two, we already computed the conditional probability density function:</p>
<p><span class="math display">\[
f_{Y|X}(y|x) = \begin{cases}
  \frac{1}{x}, &amp; 0 \leq y \leq x \\
  0,           &amp; \text{otherwise.}
\end{cases}
\]</span></p>
<p>With this knowledge on hand, compute the <span class="math inline">\(CEF[Y|X]\)</span>.</p>
<p>Once you have computed the <span class="math inline">\(CEF[Y|X]\)</span>, use this function to answer the following questions:</p>
<ul>
<li>What is the conditional expectation of <span class="math inline">\(Y\)</span>, given that <span class="math inline">\(X=x=0\)</span>?</li>
<li>What is the conditional expectation of <span class="math inline">\(Y\)</span>, given that <span class="math inline">\(X=x=0.5\)</span>?</li>
<li>What is the conditional expectation of <span class="math inline">\(X\)</span>, given that <span class="math inline">\(Y=y=0.5\)</span>?</li>
</ul>
<div id="conditional-variance" class="section level4 hasAnchor" number="5.11.0.1">
<h4><span class="header-section-number">5.11.0.1</span> Conditional Variance<a href="introdução-à-regressão-linear-univariada.html#conditional-variance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>What is the conditional variance function?<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></li>
</ul>
<p><span class="math inline">\(V[Y|X] = E[Y^2|X] - E[Y|X]^2\)</span></p>
<p>So, let’s figure out what’s happening for the <span class="math inline">\(E[Y^2|X]\)</span>.</p>
<p><span class="math inline">\(V[Y|X] = \frac{x^2}{3} - \left(\frac{x}{2}\right)^2 = \frac{x^2}{12}\)</span></p>
<p>The curious among you might want to compare this value to the <span class="math inline">\(V[Y]\)</span>. To do so, you would go back to the joint distribution that started this question, solve for the marginal distribution of <span class="math inline">\(Y\)</span>, and then compute the variance of <span class="math inline">\(Y\)</span> from that marginal.</p>
<p>Would you expect the variance will be positive or negative for these two quantities, <span class="math inline">\(V[Y]\)</span> and <span class="math inline">\(V[Y|X]\)</span>.</p>
<ul>
<li>Which of the two of these has a lower conditional variances?
<ul>
<li><span class="math inline">\(V[Y|X=0.25]\)</span>; or,</li>
<li><span class="math inline">\(V[Y|X=0.75]\)</span>.</li>
</ul></li>
<li>How does <span class="math inline">\(V[Y]\)</span> compare to <span class="math inline">\(V[Y|X=1]\)</span>? Which is larger?</li>
</ul>
</div>
<div id="conditional-expectation" class="section level3 hasAnchor" number="5.11.1">
<h3><span class="header-section-number">5.11.1</span> Conditional Expectation<a href="introdução-à-regressão-linear-univariada.html#conditional-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="minimizing-the-mse" class="section level2 hasAnchor" number="5.12">
<h2><span class="header-section-number">5.12</span> Minimizing the MSE<a href="introdução-à-regressão-linear-univariada.html#minimizing-the-mse" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="minimizing-mse" class="section level3 hasAnchor" number="5.12.1">
<h3><span class="header-section-number">5.12.1</span> Minimizing MSE<a href="introdução-à-regressão-linear-univariada.html#minimizing-mse" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Theorem 2.2.20 states,</p>
<blockquote>
<p>The CEF <span class="math inline">\(E[Y|X]\)</span> is the “best” predictor of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, where “best” means it has the smallest mean squared error (MSE).</p>
</blockquote>
<p>Oh yeah? As a breakout group, <em>ride shotgun</em> with us as we prove that the conditional expectation is the function that produces the smallest possible Mean Squared Error.</p>
<p>Specifically, <strong>you group’s task</strong> is to justify every transition from one line to the next using concepts that we have learned in the course: definitions, theorems, calculus, and algebraic operations.
:::</p>
</div>
<div id="the-pudding-aka-where-the-proof-is" class="section level3 hasAnchor" number="5.12.2">
<h3><span class="header-section-number">5.12.2</span> The pudding (aka: “Where the proof is”)<a href="introdução-à-regressão-linear-univariada.html#the-pudding-aka-where-the-proof-is" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We need to find such function <span class="math inline">\(g(X): \mathbb{R} \to \mathbb{R}\)</span> that gives the smallest mean squared error.</p>
<p>First, let MSE be defined as it is in <strong>Definition 2.1.22</strong>.</p>
<blockquote>
<p>For a random variable <span class="math inline">\(X\)</span> and constant <span class="math inline">\(c \in \mathbb{R}\)</span>, the <em>mean squared error</em> of <span class="math inline">\(X\)</span> about <span class="math inline">\(c\)</span> is <span class="math inline">\(E[(x-c)^2]\)</span>.</p>
</blockquote>
<p>Second, let us note that since <span class="math inline">\(g(X)\)</span> is just a function that maps onto <span class="math inline">\(\mathbb{R}\)</span>, that for some particular value of <span class="math inline">\(X=x\)</span>, <span class="math inline">\(g(X)\)</span> maps onto a constant value.</p>
<ul>
<li>Deriving a Function to Minimize MSE</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
  E[(Y - g(X))^2|X]
      &amp;= E[Y^2 - 2Yg(X) + g^2(X)|X]                                \\
      &amp;= E[Y^2|X] + E[-2Yg(X)|X] + E[g^2(X)|X]                     \\
      &amp;= E[Y^2|X] - 2g(X)E[Y|X] + g^2(X)E[1|X]                     \\
      &amp;= (E[Y^2|X] - E^2[Y|X]) + (E^2[Y|X] - 2g(X)E[Y|X] + g^2(X)) \\
      &amp;= V[Y|X] + (E^2[Y|X] - 2g(X)E[Y|X] + g^2(X))                \\
      &amp;= V[Y|X] + (E[Y|X] - g(X))^2                                \\
\end{aligned}
\]</span></p>
<p>Notice too that we can use the <em>Law of Iterated Expectations</em> to do something useful. (This is a good point to talk about how this theorem works in your breakout groups.)</p>
<p><span class="math display">\[
\begin{aligned}
  E[(Y-g(X))^2] &amp;= E\big[E[(Y-g(X))^2|X]\big]     \\
    &amp;=E\big[V[Y|X]+(E[Y|X]-g(X))^2\big]           \\
    &amp;=E\big[V[Y|X]\big]+E\big[(E[Y|X]-g(X))^2\big]\\
\end{aligned}
\]</span></p>
<ul>
<li><span class="math inline">\(E[V[Y|X]]\)</span> doesn’t depend on <span class="math inline">\(g\)</span>; and,</li>
<li><span class="math inline">\(E[(E[Y|X]-g(X))^2] \geq 0\)</span>.</li>
</ul>
<p><span class="math inline">\(\therefore g(X) = E[Y|X]\)</span> gives the smallest <span class="math inline">\(E[(Y-g(X))^2]\)</span></p>
</div>
<div id="the-implication" class="section level3 hasAnchor" number="5.12.3">
<h3><span class="header-section-number">5.12.3</span> The Implication<a href="introdução-à-regressão-linear-univariada.html#the-implication" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you are choosing some <span class="math inline">\(g\)</span>, you can’t do better than <span class="math inline">\(g(x) = E[Y|X=x]\)</span>.</p>
</div>
</div>
<div id="working-with-the-blp" class="section level2 hasAnchor" number="5.13">
<h2><span class="header-section-number">5.13</span> Working with the BLP<a href="introdução-à-regressão-linear-univariada.html#working-with-the-blp" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Why Linear?</p>
<ul>
<li><p>In some cases, we might try to estimate the CEF. More commonly, however, we work with linear predictors. Why?</p></li>
<li><p>We don’t know joint density function of <span class="math inline">\(Y\)</span>. So, it is “difficult” to derive a suitable CEF.</p></li>
<li><p>To estimate <em>flexible</em> functions requires considerably more data. Assumptions about distribution (e.g. a linear form) allow you to leverage those assumptions to learn ‘more’ from the same amount of data.</p></li>
<li><p>Other times, the CEF, even if we <em>could</em> produce an estimate, might be so complex that it isn’t useful or would be difficult to work with.</p></li>
<li><p>And, many times, linear predictors (which might seem trivially simple) actually do a very good job of producing predictions that are ‘close’ or useful.</p></li>
</ul>
<p>##Joint Distribution Practice</p>
<div id="professorial-mistakes-discrete-rvs" class="section level3 hasAnchor" number="5.13.1">
<h3><span class="header-section-number">5.13.1</span> Professorial Mistakes (Discrete RVs)<a href="introdução-à-regressão-linear-univariada.html#professorial-mistakes-discrete-rvs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Let the number of questions that students ask be a RV, <span class="math inline">\(X\)</span>.<br />
</p></li>
<li><p>Let <span class="math inline">\(X\)</span> take on values: <span class="math inline">\(\{1, 2, 3\}\)</span>, each with probability <span class="math inline">\(1/3\)</span>.<br />
</p></li>
<li><p>Every time a student asks a question, the instructor answers incorrectly with probability <span class="math inline">\(1/4\)</span>, independently of other questions.</p></li>
<li><p>Let the RV <span class="math inline">\(Y\)</span> be number of incorrect responses.</p></li>
<li><p><strong>Questions:</strong></p>
<ul>
<li>Compute the expectation of <span class="math inline">\(Y\)</span>, conditional on <span class="math inline">\(X\)</span>, <span class="math inline">\(E[Y|X]\)</span></li>
<li>Using the law of iterated expectations, compute <span class="math inline">\(E[Y] = E\big[E[Y|X]\big]\)</span>.</li>
</ul></li>
</ul>
</div>
<div id="continuous-blp" class="section level3 hasAnchor" number="5.13.2">
<h3><span class="header-section-number">5.13.2</span> Continuous BLP<a href="introdução-à-regressão-linear-univariada.html#continuous-blp" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Recall the PDF that we worked with earlier to produce the $CEF[Y|X].</li>
</ul>
<p><span class="math display">\[
f(x,y) =
  \begin{cases}
    2, &amp; 0 \leq x \leq 1, 0 \leq y \leq x \\
    0, &amp; otherwise
\end{cases}
\]</span></p>
<p>Find the <span class="math inline">\(BLP\)</span> for <span class="math inline">\(Y\)</span> as a function of <span class="math inline">\(X\)</span>. What, if anything, do you notice about this <span class="math inline">\(BLP\)</span> and the <span class="math inline">\(CEF\)</span>?</p>
<p>Referências
Gelman, A., &amp; Imbens, G. (2013). Why ask why? Forward causal inference and reverse causal questions (No. w19614). National Bureau of Economic Research.</p>

</div>
</div>
</div>








<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>A maior parte do curso será dedicadas a modelos preditivos, e apenas pontualmente falaremos de modelos causais<a href="introdução-à-regressão-linear-univariada.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Note, when we say “shaped” here, we’re referring to the deeper concept of a statistical functional. A statistical functional is a function of a function that maps to a real number. So, if <span class="math inline">\(T\)</span> is the functional that we’re thinking of, <span class="math inline">\(\mathcal{F}\)</span> is a family of functions that it might operate on, and <span class="math inline">\(\mathbb{R}\)</span> is the set of real numbers, a statistical functional is just <span class="math inline">\(T: \mathcal{F} \rightarrow \mathbb{R}\)</span>. The Expectation statistical functional, <span class="math inline">\(E[X]\)</span> always has the form <span class="math inline">\(\int x f_{X}(x)dx\)</span>.)<a href="introdução-à-regressão-linear-univariada.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Take a moment to strategize just a little bit before you get going on this one. There is a way to compute this value that is easier than another way to compute this value.<a href="introdução-à-regressão-linear-univariada.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introdução-à-simulação.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mgaldino/book-regression/edit/main/05-intro_reg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/mgaldino/book-regression/blob/main/05-intro_reg.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
