[["index.html", "Introdução à Regresssão para Ciências Sociais Chapter 1 Prefácio", " Introdução à Regresssão para Ciências Sociais Manoel Galdino 2023-08-07 Chapter 1 Prefácio Esse livro é, por enquanto, apenas uma repositório de notas de aula do curso de graduação da Ciências Sociais da USP, FLP xx Métodos e Técnicas de Pesquia IV, de introdução à regressão. "],["revisão-de-estatística.html", "Chapter 2 Revisão de Estatística 2.1 Fundamentals of Regreession", " Chapter 2 Revisão de Estatística 2.1 Fundamentals of Regreession "],["ref.html", "Chapter 3 ref 3.1 Revisão de estatística e probabilidade 3.2 Variância 3.3 Variável Aleatória 3.4 Esperança matemática", " Chapter 3 ref https://bookdown.org/kevin_davisross/probsim-book/introduction-to-simulation.html 3.1 Revisão de estatística e probabilidade A média de um conjunto de valores é dada pela soma dos valores, dividdo pelo número de observações. Matematicamente: \\(media = \\sum_{i=1}^n{x_i}/n\\) para observações \\(\\{ x_1, x_2, x_3, ..., x_n \\}\\) Em geral, as observações são uma amostra, e falamos de média amostral, \\(\\overline x\\). Ou seja: \\(\\overline x = \\sum_{i=1}^n{x_i}/n\\) Exercício 1. Vamos calcular, no R, a média das seguintes amostras: \\(\\{1,2,3,4,5,6,7,8,9,10\\}\\) \\(\\{5,5,5,5,5,5,5\\}\\) \\(\\{1,3,5,7,9,11\\}\\) \\(\\{-5,-4,-3,-2,-1,1,2,3,4,5\\}\\) Código no R x &lt;- c(1,2,3,4,5,6,7,8,9,10) (media_x &lt;- sum(x)/length(x)) ## [1] 5.5 x &lt;- c(5,5,5,5,5,5,5) (media_x &lt;- sum(x)/length(x)) ## [1] 5 x &lt;- c(1,3,5,7,9,11) (media_x &lt;- sum(x)/length(x)) ## [1] 6 x &lt;- c(-5,-4,-3,-2,-1,1,2,3,4,5) (media_x &lt;- sum(x)/length(x)) ## [1] 0 # ou podemos simplemsnte usar mean(x) mean(x) ## [1] 0 3.2 Variância 3.3 Variável Aleatória 3.4 Esperança matemática A esperança de uma variável aleatória discreta \\(X\\), cuja probabilidade de massa de \\(x \\in X\\) é dada por \\(p(x)\\), é definida por: \\(\\sum(x*p(x))\\) A esperança de uma v.a. contínua X, cuja densidade é \\(f(x)\\), é definida por: \\(\\int f(x)*x\\,dx\\). Similarmente, a espereança de uma função \\(h(X)\\) é dada por \\(\\int f(x)*h(x)\\,dx\\) e analogamente para o caso discreto. A variância de uma variável aleatória \\(X\\) é dada por: Definição 1. \\(Var(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]\\). A Covariância de duas v.a. \\(X\\) e \\(Y\\) é definida como: \\(Cov(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])*(Y - \\mathbb{E}[Y])]\\). Notem que \\(Cov(X,Y) = Var(X)\\). A covariância é positiva quando ambos X e Y tendem a ter valores acima (ou abaixo) de sua média simultaneamente, enquanto ela é negativa quando uma v.a. tende a ter valores acima da sua média e a outra abaixo. "],["algebra-com-esperança-variância-e-covariância.html", "Chapter 4 Algebra com Esperança, Variância e Covariância", " Chapter 4 Algebra com Esperança, Variância e Covariância Sejam \\(a\\) e \\(b\\) constantes. Linearidade da Esperença \\(\\mathbb{E}[aX + bY] =\\mathbb{E}[aX] + \\mathbb{E}[by] = a*\\mathbb{E}[X] + b*\\mathbb{E}[Y]\\) Exercício: verifique, com exemplos, que isso é verdade. Identidade da variância \\(Var(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - \\mathbb{E}^2[X]\\) A prova será demonstrada mais adiante. Identidade da Covariância \\(Voc(X,Y) = \\mathbb{E}[X*Y] - \\mathbb{E}[X]*\\mathbb{E}[Y] = \\mathbb{E}[(X - \\mathbb{E}[X])*(Y - \\mathbb{E}[Y])]\\) Exercício para o leitor. Prove que isso é verdade. 4, Covariância é simétrica \\(Cov(X,Y) = Cov(Y,X)\\) Variância não é linear \\(Var(a*X + b) = a^2*Var(x)\\) Covariância não é linear \\(Cov(a*X + b,Y) = a*Cov(Y,X)\\) # Prova da identidade da variância Vamos mostrar que \\(\\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - \\mathbb{E}^2[X]\\) Começamos expandido o quadrado da esperança: \\(Var(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[(X - \\mathbb{E}[X]) * (X - \\mathbb{E}[X])]\\). Aplicando a regra do quadrado, temos: \\(\\mathbb{E}[(X - \\mathbb{E}[X]) * (X - \\mathbb{E}[X])] = \\mathbb{E}[(X^2 - 2* \\mathbb{E}[X]*X + \\mathbb{E}[X]^2)]\\) Pela propriedade da experança, sabemos que, sejam \\(A\\) e \\(B\\) duas v.a. independentes, então \\(\\mathbb{E}[A + B] = \\mathbb{E}[A] + \\mathbb{E}[B]\\). Então: \\(Var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[2*\\mathbb{E}[X]*X] + \\mathbb{E}[\\mathbb{E}[X]^2]]\\) Outra propriedade da esperança é que, seja \\(a\\) uma constante e \\(X\\) uma v.a., então \\(\\mathbb{E}[a*X] = a*\\mathbb{E}[X]\\). \\(Var(X) = \\mathbb{E}[X^2] - 2*\\mathbb{E}[\\mathbb{E}[X]*X] + \\mathbb{E}[\\mathbb{E}[X]^2]]\\) Nós sabemos que \\(\\mathbb{E}[X]\\) é uma constante (é uma média da v.a.). E a média de uma constante é a própria constante. Portanto, \\(\\mathbb{E}[\\mathbb{E}[X]] = \\mathbb{E}[X]\\). E usaremos também que \\(\\mathbb{E}[a*X] = a*\\mathbb{E}[X]\\) e, por fim, o fato de que uma constante ao quadrado é em si uma constante. \\(Var(X) = \\mathbb{E}[X^2] - 2*\\mathbb{E}[X] * \\mathbb{E}[\\mathbb{E}[X]] + \\mathbb{E}[X]^2]\\) \\(Var(X) = \\mathbb{E}[X^2] - 2*\\mathbb{E}[X] * \\mathbb{E}[X] + \\mathbb{E}[X]^2]\\) \\(Var(X) = \\mathbb{E}[X^2] - 2*\\mathbb{E}[X]^2 + \\mathbb{E}[X]^2]\\) \\(Var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\\) Como Queriamos Demonstrar (CQD). "],["a-caucus-race-and-a-long-tale.html", "Chapter 5 A caucus-race and a long tale", " Chapter 5 A caucus-race and a long tale "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
